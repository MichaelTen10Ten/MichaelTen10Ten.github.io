<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Live2D Michelle with VITS Umamusume TTS + Poe Chat</title>
    <style>
        body {
            display: flex;
            height: 100vh;
            margin: 0;
            font-family: Arial, sans-serif;
            flex-direction: row;
            /* Desktop default */
        }

        /* On small screens, stack vertically */
        @media (max-width: 768px) {
            body {
                flex-direction: column;
            }

            #chat-container {
                width: 100% !important;
                height: 50vh;
                border-left: none;
                border-top: 1px solid #ccc;
            }

            #live2d-container {
                height: 50vh;
            }
        }

        #live2d-container {
            flex: 1;
            background: #f0f8ff;
            position: relative;
            overflow: hidden;
        }

        #canvas {
            display: block;
            width: 100%;
            height: 100%;
        }

        #chat-container {
            width: 380px;
            display: flex;
            flex-direction: column;
            padding: 15px;
            background: #fff;
            border-left: 1px solid #ccc;
        }

        #chat-history {
            flex: 1;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            margin-bottom: 10px;
            background: #fafafa;
            border-radius: 6px;
        }

        .message {
            margin: 8px 0;
            padding: 8px 12px;
            border-radius: 12px;
            max-width: 85%;
        }

        .user {
            background: #007bff;
            color: white;
            align-self: flex-end;
        }

        .bot {
            background: #e9ecef;
            color: #333;
            align-self: flex-start;
        }

        input,
        button {
            width: 100%;
            padding: 10px;
            margin: 6px 0;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box;
        }

        button {
            background: #28a745;
            color: white;
            border: none;
            cursor: pointer;
        }

        button:hover {
            background: #218838;
        }

        #status {
            color: #555;
            font-size: 0.9em;
            margin-top: 5px;
            text-align: center;
        }

        #model-error {
            position: absolute;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            color: red;
            background: rgba(255, 255, 255, 0.8);
            padding: 10px;
            border-radius: 8px;
            display: none;
        }

        #mic-btn.recording {
            background: #dc3545 !important;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.1);
            }

            100% {
                transform: scale(1);
            }
        }
    </style>

    <!-- Live2D scripts -->
    <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi.js@7.4.2/dist/pixi.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RaSan147/pixi-live2d-display@v0.5.0-ls-8/dist/cubism4.min.js"></script>
</head>

<body>

    <div id="live2d-container">
        <canvas id="canvas"></canvas>
        <div id="model-error">Live2D model failed to load. Check console & file path.</div>
    </div>
    <div id="chat-container">
        <div id="status">
            <span style="color: #007bff; font-weight: bold;">Model By</span>
        </div>
        <div id="status">
            <span style="color: #007bff; font-weight: bold;">Art:koahri1</span>
        </div>
        <div id="status">
            <span style="color: #007bff; font-weight: bold;">Live2D:MedL2D</span>
        </div>
        <div id="status">
            <span id="thinking-msg" style="display: none; color: #007bff; font-weight: bold;">Michelle is
                thinking...ðŸ’­</span>
            <div id="progress-container"
                style="display: none; width: 100%; background: #eee; border-radius: 10px; margin-top: 5px; height: 10px; overflow: hidden;">
                <div id="progress-bar" style="width: 0%; height: 100%; background: #28a745; transition: width 0.3s;">
                </div>
            </div>
            <br>
        </div>
        <div style="display: flex; gap: 5px; margin-bottom: 10px;">
            <button onclick="saveSummaryToFile()" style="background: #007bff; font-size: 12px;">ðŸ“¥ Save Memory
                (.json)</button>
            <button onclick="document.getElementById('file-upload').click()"
                style="background: #6c757d; font-size: 12px;">ðŸ“¤ Load Memory</button>
            <button onclick="clearChat()" style="background: #dc3545; font-size: 12px;">Reset</button>
            <input type="file" id="file-upload" style="display: none;" accept=".json"
                onchange="loadSummaryFromFile(event)">
        </div>
        <div id="chat-history"></div>
        <input id="api-key" type="password" placeholder="Paste your Poe API Key here">

        <div style="display: flex; gap: 5px;">
            <input id="question" type="text" placeholder="Ask a question..." style="flex: 1;">
            <button id="mic-btn" style="width: 50px; background: #6c757d;">ðŸŽ¤</button>
        </div>

        <button onclick="sendQuestion()">Send</button>
        <script>
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Live2D Setup
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            let isThinking = false; // Tracks if the model should be tilting
            let nodStart = 0;
            const nodDuration = 600; // Total time for the nod in milliseconds
            let isTyping = false;
            let lastTypingTime = 0;
            let gazeTarget = { x: 0, y: 0 }; // 0 is center, 1 is right/down, -1 is left/up
            let model;
            async function initLive2D() {
                const canvas = document.getElementById('canvas');

                app = new PIXI.Application({
                    view: canvas,
                    autoStart: true,
                    resizeTo: document.getElementById('live2d-container'), // Resize to parent div
                    backgroundColor: 0xf0f8ff,
                    antialias: true,
                    autoDensity: true,
                    resolution: window.devicePixelRatio || 1
                });

                const modelPath = 'source/michelle_source/pachirisu anime girl - top half.model3.json';

                try {
                    model = await PIXI.live2d.Live2DModel.from(modelPath, {
                        autoHitTest: false,
                        autoFocus: false,
                    });
                    app.stage.addChild(model);

                    // This function handles the scaling so it doesn't crop
                    const fitModel = () => {
                        if (!model) return;

                        // Calculate scale to fit the container (adjust 0.9 to change "zoom")
                        const scaleX = (app.screen.width / model.width) * 0.8;
                        const scaleY = (app.screen.height / model.height) * 0.8;
                        const finalScale = Math.min(scaleX, scaleY);

                        model.scale.set(finalScale);

                        // Center the model
                        model.anchor.set(0.5, 0.5);
                        model.position.set(app.screen.width / 2, app.screen.height / 1.5);
                    };

                    // Call once on load
                    fitModel();

                    // Call every time the window resizes
                    app.renderer.on('resize', fitModel);
                } catch (err) {
                    console.error("Live2D load failed:", err);
                    document.getElementById('model-error').style.display = 'block';
                }
            }
            function resizeCanvas() {
                if (!app || !model) return;

                const container = document.getElementById('live2d-container');
                const screenWidth = container.clientWidth;
                const screenHeight = container.clientHeight;
                const targetRatio = 16 / 9;

                let newWidth, newHeight;

                // Calculate dimensions to fit 16:9 inside the container
                if (screenWidth / screenHeight > targetRatio) {
                    newHeight = screenHeight;
                    newWidth = screenHeight * targetRatio;
                } else {
                    newWidth = screenWidth;
                    newHeight = screenWidth / targetRatio;
                }

                // Resize the renderer
                app.renderer.resize(newWidth, newHeight);

                // Reposition the model relative to the NEW canvas size
                model.scale.set(1); // Adjust this base scale as needed
                model.anchor.set(0.5, 0.5);
                model.position.set(newWidth / 2, newHeight * 0.6);
            }
            window.addEventListener('resize', resizeCanvas);
            initLive2D().catch(err => console.error(err));

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Chat & System prompt (force English output)
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const messages = [{
                role: "system",
                content: `You are a cute girl named Michelle, created by Michael Ten.
- Always reply in English first, then Japanese after "|||".
- Keep the Japanese natural (using "chan", "desu", etc.).
- If a section labeled [PAST MEMORY] is present, use it to personalize your very first response to the user. 
- Mention something specific from that memory so the user knows you remember them.`
            }];

            const chatHistory = document.getElementById('chat-history');

            function addMessage(role, content) {
                const div = document.createElement('div');
                div.classList.add('message', role);
                div.textContent = content;
                chatHistory.appendChild(div);
                chatHistory.scrollTop = chatHistory.scrollHeight;
            }

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // TTS with Pre-fetching and Recursive Splitting
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            async function speak(text) {
                if (typeof text !== 'string' || !text.trim()) return;

                const thinkingMsg = document.getElementById('thinking-msg');

                try {
                    // Show "Michelle is thinking"
                    thinkingMsg.style.display = 'inline';

                    // 1. Get all audio blobs (recursively splitting if needed)
                    const audioBlobs = await getAudioChunks(text);

                    // Hide "thinking" once all audio is ready to play
                    thinkingMsg.style.display = 'none';

                    // 2. Play all blobs in sequence
                    await playAudioSequence(audioBlobs);

                } catch (err) {
                    console.error("Total TTS Failure:", err);
                    thinkingMsg.style.display = 'none'; // Hide on error
                    fallbackBrowserTTS(text);
                }
            }

            /**
             * Recursively tries to fetch audio. 
             * If the API fails, it splits the text and tries to get chunks for both halves.
             */
            async function getAudioChunks(text) {
                const progressBar = document.getElementById('progress-bar');
                const progressContainer = document.getElementById('progress-container');

                // Show the bar at the start
                progressContainer.style.display = 'block';
                progressBar.style.width = '0%';

                // Helper to split text into chunks based on punctuation
                const sentences = text.match(/[^.!?ã€‚ï¼ï¼Ÿ]+[.!?ã€‚ï¼ï¼Ÿ]?/g) || [text];
                const totalSentences = sentences.length;
                let loadedSentences = 0;
                const blobs = [];

                for (const sentence of sentences) {
                    const trimmed = sentence.trim();
                    if (!trimmed) continue;

                    try {
                        const blob = await fetchSingleAudioBlob(trimmed);
                        blobs.push(blob);

                        // Update progress bar
                        loadedSentences++;
                        const percent = (loadedSentences / totalSentences) * 100;
                        progressBar.style.width = percent + '%';
                    } catch (err) {
                        console.warn("Chunk failed:", trimmed, err);
                    }
                }

                // Hide bar after a short delay so the user sees it hit 100%
                setTimeout(() => {
                    progressContainer.style.display = 'none';
                    progressBar.style.width = '0%';
                }, 500);

                return blobs;
            }

            /**
             * Logic to fetch a single audio file from Gradio
             */
            async function fetchSingleAudioBlob(text) {
                const base_url = "https://plachta-vits-umamusume-voice-synthesizer.hf.space/gradio_api/call/tts_fn";
                const payload = {
                    data: [
                        text,
                        "æ—©æŸš Sayu (Genshin Impact)",  // cute female voice
                        "æ—¥æœ¬èªž",  // Japanese
                        1,        // speed/preset
                        false      // some flag (emotion?)
                    ]
                };

                const submitRes = await fetch(base_url, {
                    method: 'POST',
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(payload)
                });
                const submitData = await submitRes.json();
                if (!submitData.event_id) throw new Error("No event_id");

                const pollRes = await fetch(`${base_url}/${submitData.event_id}`);
                const pollText = await pollRes.text();

                let audioUrl = null;
                const lines = pollText.split('\n');
                for (const line of lines) {
                    if (line.startsWith("data:")) {
                        const result = JSON.parse(line.replace("data: ", ""));
                        if (Array.isArray(result) && result[1]?.url) {
                            audioUrl = result[1].url;
                            break;
                        }
                    }
                }

                if (!audioUrl) throw new Error("Audio URL not found");

                // Convert URL to Blob to ensure we "have" the data before playing
                const audioRes = await fetch(audioUrl);
                return await audioRes.blob();
            }

            /**
 * Plays an array of Blobs one after another
 */
            // Global Audio Context and Analyser
            let audioContext = null;
            let analyser = null;
            let animationFrameId = null;

            function setupAudioAnalysis(audioElement) {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Create analyser
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                const source = audioContext.createMediaElementSource(audioElement);
                source.connect(analyser);
                analyser.connect(audioContext.destination);

                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function update() {
                    if (!model?.internalModel?.coreModel) return;

                    analyser.getByteFrequencyData(dataArray);

                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    let average = sum / bufferLength;

                    // Map volume (0-255) to Live2D parameter (0.0-1.0)
                    // Sensitivity 2.0 helps the mouth open wider for quieter sounds
                    let mouthValue = Math.min(1.0, (average / 128));

                    // USE THE EXACT ID FROM YOUR CDI3.JSON: "ParamMouthOpenY"
                    model.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthValue);

                    animationFrameId = requestAnimationFrame(update);
                }
                update();
            }

            async function playAudioSequence(blobs) {
                for (const blob of blobs) {
                    const url = URL.createObjectURL(blob);
                    const audio = new Audio(url);
                    audio.crossOrigin = "anonymous"; // Prevents CORS issues with analysis

                    await new Promise((resolve, reject) => {
                        audio.onplay = () => {
                            if (audioContext?.state === 'suspended') {
                                audioContext.resume();
                            }

                            // Trigger the nod only on the very first chunk of a sentence
                            if (blobs.indexOf(blob) === 0) {
                                nodStart = performance.now();
                            }

                            setupAudioAnalysis(audio);
                            document.getElementById('thinking-msg').style.display = 'none';
                        };
                        audio.onended = () => {
                            cancelAnimationFrame(animationFrameId);
                            // Reset mouth to closed
                            model.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', 0);
                            URL.revokeObjectURL(url);
                            resolve();
                        };
                        audio.onerror = reject;
                        audio.play().catch(reject);
                    });
                }
            }

            /**
             * Finds the punctuation mark closest to the center
             */
            function findSplitPoint(text) {
                const punctuations = /[.!?;]/g;
                const matches = Array.from(text.matchAll(punctuations));
                if (matches.length === 0) return -1;

                const mid = text.length / 2;
                let bestMatch = matches[0];
                matches.forEach(match => {
                    if (Math.abs(match.index - mid) < Math.abs(bestMatch.index - mid)) {
                        bestMatch = match;
                    }
                });
                return bestMatch.index;
            }

            function fallbackBrowserTTS(text) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = "en-US";
                utterance.pitch = 1.85;
                utterance.onstart = startMouthAnimation;
                utterance.onend = stopMouthAnimation;
                speechSynthesis.speak(utterance);
            }
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Send question
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const questionBox = document.getElementById('question');

            questionBox.addEventListener('input', () => {
                isTyping = true;
                lastTypingTime = performance.now();
            });
            async function sendQuestion() {
                isTyping = false;
                const apiKey = document.getElementById('api-key').value.trim();
                if (!apiKey) { alert('Please enter Poe API Key'); return; }

                const question = document.getElementById('question').value.trim();
                if (!question) return;
                // Reset gaze and start thinking animation
                isTyping = false;
                isThinking = true;

                addMessage('user', question);
                document.getElementById('question').value = '';
                messages.push({ role: 'user', content: question });

                const thinkingMsg = document.getElementById('thinking-msg');
                thinkingMsg.style.display = 'inline';

                try {
                    const res = await fetch('https://api.poe.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                        body: JSON.stringify({ model: 'gpt-4o-mini', messages, stream: false })
                    });

                    const data = await res.json();
                    let fullReply = data?.choices?.[0]?.message?.content?.trim?.() || '';

                    let englishText = fullReply;
                    let japaneseText = fullReply;
                    if (fullReply.includes('|||')) {
                        const parts = fullReply.split('|||');
                        englishText = parts[0].trim();
                        japaneseText = parts[1].trim();
                    }

                    // 1. Fetch all audio (this updates the progress bar automatically)
                    const audioBlobs = await getAudioChunks(japaneseText);
                    // Stop thinking tilt just before she starts talking/nodding
                    isThinking = false;
                    thinkingMsg.style.display = 'none';
                    // 2. Clear status and show message
                    addMessage('bot', englishText);
                    messages.push({ role: 'assistant', content: fullReply });
                    localStorage.setItem('michelle_autosave', JSON.stringify(messages));
                    // 3. Start speaking immediately
                    await playAudioSequence(audioBlobs);

                } catch (err) {
                    console.error(err); console.error(err);
                    isThinking = false; // Reset on error
                    thinkingMsg.style.display = 'none';
                    document.getElementById('progress-container').style.display = 'none';
                    addMessage('bot', 'Error... please check API key or connection.');
                }
            }

            window.sendQuestion = sendQuestion;
            document.getElementById('question').addEventListener('keypress', e => {
                if (e.key === 'Enter') { e.preventDefault(); sendQuestion(); }
            });

            // Debug voices
            speechSynthesis.onvoiceschanged = () => {
                const voices = speechSynthesis.getVoices();
                const cantonese = voices.filter(v => v.lang === "zh-HK");
                if (cantonese.length) console.log("Browser zh-HK voices:", cantonese.map(v => v.name));
            };
            speechSynthesis.getVoices();

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Speech to Text (STT) Setup
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const micBtn = document.getElementById('mic-btn');
            const questionInput = document.getElementById('question');

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

            if (SpeechRecognition) {
                const recognition = new SpeechRecognition();
                recognition.lang = 'en-US'; // You can change this to 'zh-HK' or 'ja-JP'
                recognition.interimResults = false;
                recognition.continuous = false;

                micBtn.addEventListener('click', () => {
                    try {
                        recognition.start();
                    } catch (e) {
                        recognition.stop();
                    }
                });

                recognition.onstart = () => {
                    micBtn.classList.add('recording');
                    micBtn.textContent = 'ðŸ›‘';
                    questionInput.placeholder = "Listening...";
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    questionInput.value = transcript;
                    // Automatically send the question after voice input
                    sendQuestion();
                };

                recognition.onend = () => {
                    micBtn.classList.remove('recording');
                    micBtn.textContent = 'ðŸŽ¤';
                    questionInput.placeholder = "Ask a question...";
                };

                recognition.onerror = (event) => {
                    console.error("Speech Recognition Error: ", event.error);
                    micBtn.classList.remove('recording');
                    micBtn.textContent = 'ðŸŽ¤';
                };
            } else {
                micBtn.style.display = 'none';
                console.warn("Speech Recognition not supported in this browser.");
            }
            // --- Idle Animations (Blinking & Breathing) ---
            let lastBlinkTime = 0;
            let blinkDuration = 150;
            let nextBlinkInterval = 3000;

            function updateIdleAnimations(currentTime) {
                if (!model?.internalModel?.coreModel) {
                    requestAnimationFrame(updateIdleAnimations);
                    return;
                }

                const coreModel = model.internalModel.coreModel;

                // --- DYNAMIC GAZE, NOD, & TILT LOGIC ---
                const now = currentTime;
                if (isTyping && now - lastTypingTime > 2000) {
                    isTyping = false;
                }

                // 1. Calculate Base Gaze (typing or center)
                let targetX = isTyping ? 25 : 0;
                let targetY = isTyping ? -15 : 0;
                let targetZ = 0; // Default tilt

                // 2. Thinking Tilt Override (Z-axis)
                if (isThinking) {
                    // Slower, curious side-to-side tilt
                    targetZ = Math.sin(now / 600) * 10;
                    targetY = -5; // Look slightly up/neutral while thinking
                }

                // 3. Nodding Override (Y-axis)
                let nodOffset = 0;
                if (nodStart > 0) {
                    const elapsedNod = now - nodStart;
                    if (elapsedNod < nodDuration) {
                        nodOffset = Math.sin((elapsedNod / nodDuration) * Math.PI) * -15;
                    } else {
                        nodStart = 0;
                    }
                }

                // 4. Smooth Interpolation
                let currentX = coreModel.getParameterValueById('ParamAngleX');
                let currentY = coreModel.getParameterValueById('ParamAngleY');
                let currentZ = coreModel.getParameterValueById('ParamAngleZ');

                let newX = currentX + (targetX - currentX) * 0.1;
                let newY = currentY + ((targetY + nodOffset) - currentY) * 0.1;
                let newZ = currentZ + (targetZ - currentZ) * 0.05; // Z moves a bit slower for "floaty" feel

                coreModel.setParameterValueById('ParamAngleX', newX);
                coreModel.setParameterValueById('ParamAngleY', newY);
                coreModel.setParameterValueById('ParamAngleZ', newZ);

                // Eye movement follows head
                coreModel.setParameterValueById('ParamEyeBallX', newX / 25);
                coreModel.setParameterValueById('ParamEyeBallY', newY / 15);                // Apply slight body tilt for realism
                coreModel.setParameterValueById('ParamBodyAngleX', newX / 2);
                // --- BREATHING ---
                let breathValue = (Math.sin(currentTime / 1000 * 0.5) + 1) / 2;
                coreModel.setParameterValueById('ParamBreath', breathValue);

                // --- BLINKING ---
                const elapsed = currentTime - lastBlinkTime;
                if (elapsed > nextBlinkInterval) {
                    let blinkProgress = (elapsed - nextBlinkInterval) / blinkDuration;
                    if (blinkProgress <= 1) {
                        let eyeValue = 0.5 + 0.5 * Math.cos(blinkProgress * Math.PI * 2);
                        coreModel.setParameterValueById('ParamEyeLOpen', eyeValue);
                        coreModel.setParameterValueById('ParamEyeROpen', eyeValue);
                    } else {
                        coreModel.setParameterValueById('ParamEyeLOpen', 1.0);
                        coreModel.setParameterValueById('ParamEyeROpen', 1.0);
                        lastBlinkTime = currentTime;
                        nextBlinkInterval = 2000 + Math.random() * 5000;
                    }
                }

                requestAnimationFrame(updateIdleAnimations);
            }

            // Start the loop
            requestAnimationFrame(updateIdleAnimations);
            // --- SAVE / LOAD LOGIC ---

            // --- FILE-BASED SAVE / LOAD ---

            async function saveSummaryToFile() {
                const apiKey = document.getElementById('api-key').value.trim();
                if (!apiKey || messages.length < 3) {
                    alert("Need a conversation to summarize first!");
                    return;
                }

                try {
                    // 1. Get the summary from AI
                    const summaryRequest = [
                        ...messages,
                        { role: "user", content: "Summarize our conversation into a short paragraph for your memory. Write it in the third person." }
                    ];

                    const res = await fetch('https://api.poe.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                        body: JSON.stringify({ model: 'gpt-4o-mini', messages: summaryRequest, stream: false })
                    });

                    const data = await res.json();
                    const summary = data?.choices?.[0]?.message?.content?.trim?.() || '';

                    // 2. Prepare the data object
                    const saveData = {
                        botName: "Michelle",
                        date: new Date().toLocaleDateString(),
                        summary: summary,
                        systemPrompt: messages[0].content
                    };

                    // 3. Create the file and trigger download
                    const blob = new Blob([JSON.stringify(saveData, null, 2)], { type: "application/json" });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `michelle_memory_${new Date().getTime()}.json`;
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);

                } catch (err) {
                    console.error(err);
                    alert("Failed to save memory file.");
                }
            }

            function loadSummaryFromFile(event) {
                const file = event.target.files[0];
                if (!file) return;

                const reader = new FileReader();
                reader.onload = async function (e) {
                    try {
                        const decoded = JSON.parse(e.target.result);

                        // 1. Reconstruct Michelle's brain with the memory
                        const enhancedSystemPrompt = `${decoded.systemPrompt}\n\n[PAST MEMORY]: ${decoded.summary}`;

                        messages.length = 0;
                        messages.push({ role: "system", content: enhancedSystemPrompt });

                        // 2. Clear UI and show a loading state
                        chatHistory.innerHTML = '';
                        const thinkingMsg = document.getElementById('thinking-msg');
                        thinkingMsg.style.display = 'inline';
                        isThinking = true;

                        // 3. Automatically trigger a "Greeting" request to the AI
                        // We push a hidden prompt asking her to say hi based on her memory
                        const res = await fetch('https://api.poe.com/v1/chat/completions', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                                'Authorization': `Bearer ${document.getElementById('api-key').value.trim()}`
                            },
                            body: JSON.stringify({
                                model: 'gpt-4o-mini',
                                messages: [...messages, { role: "user", content: "I'm back! Can you greet me?" }],
                                stream: false
                            })
                        });

                        const data = await res.json();
                        let fullReply = data?.choices?.[0]?.message?.content?.trim?.() || '';

                        // 4. Handle the reply (Split English/Japanese)
                        let englishText = fullReply.split('|||')[0].trim();
                        let japaneseText = fullReply.includes('|||') ? fullReply.split('|||')[1].trim() : fullReply;

                        // 5. Speak and Display
                        isThinking = false;
                        thinkingMsg.style.display = 'none';
                        addMessage('bot', englishText);
                        messages.push({ role: 'assistant', content: fullReply });

                        const audioBlobs = await getAudioChunks(japaneseText);
                        await playAudioSequence(audioBlobs);

                    } catch (err) {
                        console.error(err);
                        alert("Error: This file is not a valid Michelle memory file.");
                    }
                };
                reader.readAsText(file);
            }

            function clearChat() {
                if (confirm("Are you sure you want to clear the entire chat?")) {
                    messages.length = 1; // Keep only system prompt
                    chatHistory.innerHTML = '';
                    localStorage.removeItem('michelle_autosave');
                    location.reload();
                }
            }

            window.addEventListener('load', () => {
                const saved = localStorage.getItem('michelle_autosave');
                if (saved) {
                    const parsed = JSON.parse(saved);
                    // Wipe default messages and load saved ones
                    messages.length = 0;
                    parsed.forEach(msg => {
                        messages.push(msg);
                        if (msg.role !== 'system') {
                            let displayContent = msg.content;
                            if (msg.role === 'assistant' && displayContent.includes('|||')) {
                                displayContent = displayContent.split('|||')[0].trim();
                            }
                            addMessage(msg.role, displayContent);
                        }
                    });
                }
            });
            async function generateAndSaveSummary() {
                const apiKey = document.getElementById('api-key').value.trim();
                if (!apiKey || messages.length < 3) return; // Need at least one exchange to summarize

                try {
                    // Create a summary prompt
                    const summaryRequest = [
                        ...messages,
                        {
                            role: "user",
                            content: "Summarize our conversation so far into a short paragraph. Focus on key facts I told you about myself and our main topics. Write it in the third person (e.g., 'The user is...')."
                        }
                    ];

                    const res = await fetch('https://api.poe.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                        body: JSON.stringify({ model: 'gpt-4o-mini', messages: summaryRequest, stream: false })
                    });

                    const data = await res.json();
                    const summary = data?.choices?.[0]?.message?.content?.trim?.() || '';

                    if (summary) {
                        // Create a "Save Block" that includes the original system prompt + the new summary
                        const saveBlock = {
                            timestamp: new Date().toLocaleString(),
                            summary: summary,
                            systemPrompt: messages[0].content // Keep Michelle's personality instructions
                        };

                        const encoded = btoa(unescape(encodeURIComponent(JSON.stringify(saveBlock))));
                        navigator.clipboard.writeText(encoded);
                        alert("Summary Save Code copied to clipboard! Michelle will remember this summary next time.");
                    }
                } catch (err) {
                    console.error("Summary failed:", err);
                    alert("Failed to generate summary.");
                }
            }
        </script>
</body>

</html>