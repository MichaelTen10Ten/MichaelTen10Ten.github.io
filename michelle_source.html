<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Live2D Michelle with VITS Umamusume TTS + Poe Chat</title>
    <style>
        body {
            display: flex;
            height: 100vh;
            margin: 0;
            font-family: Arial, sans-serif;
            flex-direction: row;
            /* Desktop default */
        }

        /* On small screens, stack vertically */
        @media (max-width: 768px) {
            body {
                flex-direction: column;
            }

            #chat-container {
                width: 100% !important;
                height: 50vh;
                border-left: none;
                border-top: 1px solid #ccc;
            }

            #live2d-container {
                height: 50vh;
            }
        }

        #live2d-container {
            flex: 1;
            background: #f0f8ff;
            position: relative;
            overflow: hidden;
        }

        #canvas {
            display: block;
            width: 100%;
            height: 100%;
        }

        #chat-container {
            width: 380px;
            display: flex;
            flex-direction: column;
            padding: 15px;
            background: #fff;
            border-left: 1px solid #ccc;
        }

        #chat-history {
            flex: 1;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            margin-bottom: 10px;
            background: #fafafa;
            border-radius: 6px;
        }

        .message {
            margin: 8px 0;
            padding: 8px 12px;
            border-radius: 12px;
            max-width: 85%;
        }

        .user {
            background: #007bff;
            color: white;
            align-self: flex-end;
        }

        .bot {
            background: #e9ecef;
            color: #333;
            align-self: flex-start;
        }

        input,
        button {
            width: 100%;
            padding: 10px;
            margin: 6px 0;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box;
        }

        button {
            background: #28a745;
            color: white;
            border: none;
            cursor: pointer;
        }

        button:hover {
            background: #218838;
        }

        #status {
            color: #555;
            font-size: 0.9em;
            margin-top: 5px;
            text-align: center;
        }

        #model-error {
            position: absolute;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            color: red;
            background: rgba(255, 255, 255, 0.8);
            padding: 10px;
            border-radius: 8px;
            display: none;
        }

        #mic-btn.recording {
            background: #dc3545 !important;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.1);
            }

            100% {
                transform: scale(1);
            }
        }
    </style>

    <!-- Live2D scripts -->
    <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi.js@7.4.2/dist/pixi.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/RaSan147/pixi-live2d-display@v0.5.0-ls-8/dist/cubism4.min.js"></script>
</head>

<body>

    <div id="live2d-container">
        <canvas id="canvas"></canvas>
        <div id="model-error">Live2D model failed to load. Check console & file path.</div>
    </div>
    <div id="chat-container">
        <div id="status">
            <span style="color: #007bff; font-weight: bold;">Model By</span>
            <span style="color: #007bff; font-weight: bold;">Art:koahri1</span>
            <span style="color: #007bff; font-weight: bold;">Live2D:MedL2D</span>

        </div>
        <div id="status">
            <span id="thinking-msg" style="display: none; color: #007bff; font-weight: bold;">Michelle is
                thinking...ðŸ’­</span>
            <div id="progress-container"
                style="display: none; width: 100%; background: #eee; border-radius: 10px; margin-top: 5px; height: 10px; overflow: hidden;">
                <div id="progress-bar" style="width: 0%; height: 100%; background: #28a745; transition: width 0.3s;">
                </div>
            </div>
            <br>
        </div>
        <div id="chat-history"></div>
        <input id="api-key" type="password" placeholder="Paste your Poe API Key here">

        <div style="display: flex; gap: 5px;">
            <input id="question" type="text" placeholder="Ask a question..." style="flex: 1;">
            <button id="mic-btn" style="width: 50px; background: #6c757d;">ðŸŽ¤</button>
        </div>

        <button onclick="sendQuestion()">Send</button>
        <script>
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Live2D Setup
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            let isTyping = false;
            let lastTypingTime = 0;
            let gazeTarget = { x: 0, y: 0 }; // 0 is center, 1 is right/down, -1 is left/up
            let model;
            async function initLive2D() {
                const canvas = document.getElementById('canvas');

                app = new PIXI.Application({
                    view: canvas,
                    autoStart: true,
                    resizeTo: document.getElementById('live2d-container'), // Resize to parent div
                    backgroundColor: 0xf0f8ff,
                    antialias: true,
                    autoDensity: true,
                    resolution: window.devicePixelRatio || 1
                });

                const modelPath = 'source/michelle_source/pachirisu anime girl - top half.model3.json';

                try {
                    model = await PIXI.live2d.Live2DModel.from(modelPath, {
                        autoHitTest: false,
                        autoFocus: false,
                    });
                    app.stage.addChild(model);

                    // This function handles the scaling so it doesn't crop
                    const fitModel = () => {
                        if (!model) return;

                        // Calculate scale to fit the container (adjust 0.9 to change "zoom")
                        const scaleX = (app.screen.width / model.width) * 0.8;
                        const scaleY = (app.screen.height / model.height) * 0.8;
                        const finalScale = Math.min(scaleX, scaleY);

                        model.scale.set(finalScale);

                        // Center the model
                        model.anchor.set(0.5, 0.5);
                        model.position.set(app.screen.width / 2, app.screen.height / 1.5);
                    };

                    // Call once on load
                    fitModel();

                    // Call every time the window resizes
                    app.renderer.on('resize', fitModel);
                } catch (err) {
                    console.error("Live2D load failed:", err);
                    document.getElementById('model-error').style.display = 'block';
                }
            }
            function resizeCanvas() {
                if (!app || !model) return;

                const container = document.getElementById('live2d-container');
                const screenWidth = container.clientWidth;
                const screenHeight = container.clientHeight;
                const targetRatio = 16 / 9;

                let newWidth, newHeight;

                // Calculate dimensions to fit 16:9 inside the container
                if (screenWidth / screenHeight > targetRatio) {
                    newHeight = screenHeight;
                    newWidth = screenHeight * targetRatio;
                } else {
                    newWidth = screenWidth;
                    newHeight = screenWidth / targetRatio;
                }

                // Resize the renderer
                app.renderer.resize(newWidth, newHeight);

                // Reposition the model relative to the NEW canvas size
                model.scale.set(1); // Adjust this base scale as needed
                model.anchor.set(0.5, 0.5);
                model.position.set(newWidth / 2, newHeight * 0.6);
            }
            window.addEventListener('resize', resizeCanvas);
            initLive2D().catch(err => console.error(err));

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Chat & System prompt (force English output)
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const messages = [{
                role: "system",
                content: `You are a cute girl named Michelle, created by Michael Ten.
- Always reply in English first.
- Then, provide a natural Japanese translation of your reply after the delimiter "|||".
- Keep the Japanese natural for a cute girl (using "chan", "desu", etc.).
- Example format: Hello there! How are you? ||| ã“ã‚“ã«ã¡ã¯ï¼å…ƒæ°—ã§ã™ã‹ï¼Ÿ`
            }];

            const chatHistory = document.getElementById('chat-history');

            function addMessage(role, content) {
                const div = document.createElement('div');
                div.classList.add('message', role);
                div.textContent = content;
                chatHistory.appendChild(div);
                chatHistory.scrollTop = chatHistory.scrollHeight;
            }

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // TTS with Pre-fetching and Recursive Splitting
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            async function speak(text) {
                if (typeof text !== 'string' || !text.trim()) return;

                const thinkingMsg = document.getElementById('thinking-msg');

                try {
                    // Show "Michelle is thinking"
                    thinkingMsg.style.display = 'inline';

                    // 1. Get all audio blobs (recursively splitting if needed)
                    const audioBlobs = await getAudioChunks(text);

                    // Hide "thinking" once all audio is ready to play
                    thinkingMsg.style.display = 'none';

                    // 2. Play all blobs in sequence
                    await playAudioSequence(audioBlobs);

                } catch (err) {
                    console.error("Total TTS Failure:", err);
                    thinkingMsg.style.display = 'none'; // Hide on error
                    fallbackBrowserTTS(text);
                }
            }

            /**
             * Recursively tries to fetch audio. 
             * If the API fails, it splits the text and tries to get chunks for both halves.
             */
            async function getAudioChunks(text) {
                const progressBar = document.getElementById('progress-bar');
                const progressContainer = document.getElementById('progress-container');

                // Show the bar at the start
                progressContainer.style.display = 'block';
                progressBar.style.width = '0%';

                // Helper to split text into chunks based on punctuation
                const sentences = text.match(/[^.!?ã€‚ï¼ï¼Ÿ]+[.!?ã€‚ï¼ï¼Ÿ]?/g) || [text];
                const totalSentences = sentences.length;
                let loadedSentences = 0;
                const blobs = [];

                for (const sentence of sentences) {
                    const trimmed = sentence.trim();
                    if (!trimmed) continue;

                    try {
                        const blob = await fetchSingleAudioBlob(trimmed);
                        blobs.push(blob);

                        // Update progress bar
                        loadedSentences++;
                        const percent = (loadedSentences / totalSentences) * 100;
                        progressBar.style.width = percent + '%';
                    } catch (err) {
                        console.warn("Chunk failed:", trimmed, err);
                    }
                }

                // Hide bar after a short delay so the user sees it hit 100%
                setTimeout(() => {
                    progressContainer.style.display = 'none';
                    progressBar.style.width = '0%';
                }, 500);

                return blobs;
            }

            /**
             * Logic to fetch a single audio file from Gradio
             */
            async function fetchSingleAudioBlob(text) {
                const base_url = "https://plachta-vits-umamusume-voice-synthesizer.hf.space/gradio_api/call/tts_fn";
                const payload = {
                    data: [
                        text,
                        "æ—©æŸš Sayu (Genshin Impact)",  // cute female voice
                        "æ—¥æœ¬èªž",  // Japanese
                        1,        // speed/preset
                        false      // some flag (emotion?)
                    ]
                };

                const submitRes = await fetch(base_url, {
                    method: 'POST',
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(payload)
                });
                const submitData = await submitRes.json();
                if (!submitData.event_id) throw new Error("No event_id");

                const pollRes = await fetch(`${base_url}/${submitData.event_id}`);
                const pollText = await pollRes.text();

                let audioUrl = null;
                const lines = pollText.split('\n');
                for (const line of lines) {
                    if (line.startsWith("data:")) {
                        const result = JSON.parse(line.replace("data: ", ""));
                        if (Array.isArray(result) && result[1]?.url) {
                            audioUrl = result[1].url;
                            break;
                        }
                    }
                }

                if (!audioUrl) throw new Error("Audio URL not found");

                // Convert URL to Blob to ensure we "have" the data before playing
                const audioRes = await fetch(audioUrl);
                return await audioRes.blob();
            }

            /**
 * Plays an array of Blobs one after another
 */
            // Global Audio Context and Analyser
            let audioContext = null;
            let analyser = null;
            let animationFrameId = null;

            function setupAudioAnalysis(audioElement) {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Create analyser
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                const source = audioContext.createMediaElementSource(audioElement);
                source.connect(analyser);
                analyser.connect(audioContext.destination);

                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function update() {
                    if (!model?.internalModel?.coreModel) return;

                    analyser.getByteFrequencyData(dataArray);

                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    let average = sum / bufferLength;

                    // Map volume (0-255) to Live2D parameter (0.0-1.0)
                    // Sensitivity 2.0 helps the mouth open wider for quieter sounds
                    let mouthValue = Math.min(1.0, (average / 128));

                    // USE THE EXACT ID FROM YOUR CDI3.JSON: "ParamMouthOpenY"
                    model.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthValue);

                    animationFrameId = requestAnimationFrame(update);
                }
                update();
            }

            async function playAudioSequence(blobs) {
                for (const blob of blobs) {
                    const url = URL.createObjectURL(blob);
                    const audio = new Audio(url);
                    audio.crossOrigin = "anonymous"; // Prevents CORS issues with analysis

                    await new Promise((resolve, reject) => {
                        audio.onplay = () => {
                            if (audioContext?.state === 'suspended') {
                                audioContext.resume();
                            }
                            setupAudioAnalysis(audio);
                            document.getElementById('thinking-msg').style.display = 'none';
                        };
                        audio.onended = () => {
                            cancelAnimationFrame(animationFrameId);
                            // Reset mouth to closed
                            model.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', 0);
                            URL.revokeObjectURL(url);
                            resolve();
                        };
                        audio.onerror = reject;
                        audio.play().catch(reject);
                    });
                }
            }

            /**
             * Finds the punctuation mark closest to the center
             */
            function findSplitPoint(text) {
                const punctuations = /[.!?;]/g;
                const matches = Array.from(text.matchAll(punctuations));
                if (matches.length === 0) return -1;

                const mid = text.length / 2;
                let bestMatch = matches[0];
                matches.forEach(match => {
                    if (Math.abs(match.index - mid) < Math.abs(bestMatch.index - mid)) {
                        bestMatch = match;
                    }
                });
                return bestMatch.index;
            }

            function fallbackBrowserTTS(text) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = "en-US";
                utterance.pitch = 1.85;
                utterance.onstart = startMouthAnimation;
                utterance.onend = stopMouthAnimation;
                speechSynthesis.speak(utterance);
            }
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Send question
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const questionBox = document.getElementById('question');

            questionBox.addEventListener('input', () => {
                isTyping = true;
                lastTypingTime = performance.now();
            });
            async function sendQuestion() {
                isTyping = false;
                const apiKey = document.getElementById('api-key').value.trim();
                if (!apiKey) { alert('Please enter Poe API Key'); return; }

                const question = document.getElementById('question').value.trim();
                if (!question) return;

                addMessage('user', question);
                document.getElementById('question').value = '';
                messages.push({ role: 'user', content: question });

                const thinkingMsg = document.getElementById('thinking-msg');
                thinkingMsg.style.display = 'inline';

                try {
                    const res = await fetch('https://api.poe.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                        body: JSON.stringify({ model: 'gpt-4o-mini', messages, stream: false })
                    });

                    const data = await res.json();
                    let fullReply = data?.choices?.[0]?.message?.content?.trim?.() || '';

                    let englishText = fullReply;
                    let japaneseText = fullReply;
                    if (fullReply.includes('|||')) {
                        const parts = fullReply.split('|||');
                        englishText = parts[0].trim();
                        japaneseText = parts[1].trim();
                    }

                    // 1. Fetch all audio (this updates the progress bar automatically)
                    const audioBlobs = await getAudioChunks(japaneseText);

                    // 2. Clear status and show message
                    thinkingMsg.style.display = 'none';
                    addMessage('bot', englishText);
                    messages.push({ role: 'assistant', content: fullReply });

                    // 3. Start speaking immediately
                    await playAudioSequence(audioBlobs);

                } catch (err) {
                    console.error(err);
                    thinkingMsg.style.display = 'none';
                    document.getElementById('progress-container').style.display = 'none';
                    addMessage('bot', 'Error... please check API key or connection.');
                }
            }

            window.sendQuestion = sendQuestion;
            document.getElementById('question').addEventListener('keypress', e => {
                if (e.key === 'Enter') { e.preventDefault(); sendQuestion(); }
            });

            // Debug voices
            speechSynthesis.onvoiceschanged = () => {
                const voices = speechSynthesis.getVoices();
                const cantonese = voices.filter(v => v.lang === "zh-HK");
                if (cantonese.length) console.log("Browser zh-HK voices:", cantonese.map(v => v.name));
            };
            speechSynthesis.getVoices();

            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // Speech to Text (STT) Setup
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const micBtn = document.getElementById('mic-btn');
            const questionInput = document.getElementById('question');

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

            if (SpeechRecognition) {
                const recognition = new SpeechRecognition();
                recognition.lang = 'en-US'; // You can change this to 'zh-HK' or 'ja-JP'
                recognition.interimResults = false;
                recognition.continuous = false;

                micBtn.addEventListener('click', () => {
                    try {
                        recognition.start();
                    } catch (e) {
                        recognition.stop();
                    }
                });

                recognition.onstart = () => {
                    micBtn.classList.add('recording');
                    micBtn.textContent = 'ðŸ›‘';
                    questionInput.placeholder = "Listening...";
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    questionInput.value = transcript;
                    // Automatically send the question after voice input
                    sendQuestion();
                };

                recognition.onend = () => {
                    micBtn.classList.remove('recording');
                    micBtn.textContent = 'ðŸŽ¤';
                    questionInput.placeholder = "Ask a question...";
                };

                recognition.onerror = (event) => {
                    console.error("Speech Recognition Error: ", event.error);
                    micBtn.classList.remove('recording');
                    micBtn.textContent = 'ðŸŽ¤';
                };
            } else {
                micBtn.style.display = 'none';
                console.warn("Speech Recognition not supported in this browser.");
            }
            // --- Idle Animations (Blinking & Breathing) ---
            let lastBlinkTime = 0;
            let blinkDuration = 150;
            let nextBlinkInterval = 3000;

            function updateIdleAnimations(currentTime) {
                if (!model?.internalModel?.coreModel) {
                    requestAnimationFrame(updateIdleAnimations);
                    return;
                }

                const coreModel = model.internalModel.coreModel;

                // --- DYNAMIC GAZE LOGIC ---
                const now = currentTime;
                // Check if user stopped typing more than 2 seconds ago
                if (isTyping && now - lastTypingTime > 2000) {
                    isTyping = false;
                }

                // Target values: If typing, look right (1.0) and slightly down (0.5). If not, look center (0)
                const targetX = isTyping ? 25 : 0; // Head Angle X usually ranges -30 to 30
                const targetY = isTyping ? -15 : 0; // Head Angle Y (Negative is usually looking down)

                // Smooth Interpolation (Lerp) so the head doesn't snap instantly
                // We use a simple formula: current = current + (target - current) * speed
                let currentX = coreModel.getParameterValueById('ParamAngleX');
                let currentY = coreModel.getParameterValueById('ParamAngleY');

                let newX = currentX + (targetX - currentX) * 0.1;
                let newY = currentY + (targetY - currentY) * 0.1;

                // Apply to Head
                coreModel.setParameterValueById('ParamAngleX', newX);
                coreModel.setParameterValueById('ParamAngleY', newY);

                // Apply to Eyes (optional, makes the gaze more intense)
                coreModel.setParameterValueById('ParamEyeBallX', newX / 25);
                coreModel.setParameterValueById('ParamEyeBallY', newY / 15);

                // Apply slight body tilt for realism
                coreModel.setParameterValueById('ParamBodyAngleX', newX / 2);
                // --- BREATHING ---
                let breathValue = (Math.sin(currentTime / 1000 * 0.5) + 1) / 2;
                coreModel.setParameterValueById('ParamBreath', breathValue);

                // --- BLINKING ---
                const elapsed = currentTime - lastBlinkTime;
                if (elapsed > nextBlinkInterval) {
                    let blinkProgress = (elapsed - nextBlinkInterval) / blinkDuration;
                    if (blinkProgress <= 1) {
                        let eyeValue = 0.5 + 0.5 * Math.cos(blinkProgress * Math.PI * 2);
                        coreModel.setParameterValueById('ParamEyeLOpen', eyeValue);
                        coreModel.setParameterValueById('ParamEyeROpen', eyeValue);
                    } else {
                        coreModel.setParameterValueById('ParamEyeLOpen', 1.0);
                        coreModel.setParameterValueById('ParamEyeROpen', 1.0);
                        lastBlinkTime = currentTime;
                        nextBlinkInterval = 2000 + Math.random() * 5000;
                    }
                }

                requestAnimationFrame(updateIdleAnimations);
            }

            // Start the loop
            requestAnimationFrame(updateIdleAnimations);
        </script>
</body>

</html>